
const jobsList = [
    {
        id: 1,
        CandidateName:'John Smith',
        jobTitle: "MERN Stack Developer",
        company: "TCS",
        location: "Hyderabad",
        platform: "LinkedIn",
        isApply: true,
        postStatus: "Apply",
        matchedAt: "14-Jun-23",
        score: "25.02%",
        hrEmail: "hr@tcs.com",
        jobLink: "https://www.linkedin.com",
        jobDescription: {
            responsibility: [
                "Ensuring an uninterrupted flow of data from the various sources by crawling the web",
                "Extracting & managing large volumes of structured and unstructured data, with the ability to parse data into standardized format for ingestion into data sources",
                "Actively participate in troubleshooting, debugging & maintaining the broken crawlers",
                "Scraping difficult websites by deploying anti-blocking and anti-captcha tools",
                "Strong data analysis skills working with data quality, data consolidation and data wrangling",
                "Solid understanding of Data structures and Algorithms",
                "Comply with coding standards and technical design"
            ],
            requirements: [
                "Education: B.E / B.Tech / BSC/ MSC",
                "Experience : 0-1 year",
                "KeySkills: Python, Perl, Scrapy, Selenium, headless browsers, Puppeteer, Node.js, Beautiful Soup, sVN, GitHub",
                "Experience of complex crawling like captcha, recaptcha and bypassing proxy, etc",
                "Regular Expressions",
                "Basic understanding of front-end technologies, such as JavaScript, HTML5, and CSS3.",
                "Strong fundamental C.S. skills (Data structures, algorithms, multi-threading, etc.)",
                "Good communication skills (must)",
                "Experience with web crawler projects is a plus."
            ]
        }
    },
    {
        id: 2,
        CandidateName:'Janifer decibel',
        jobTitle: "Frontend Developer",
        company: "Wipro",
        location: "Chennai",
        platform: "Monster",
        isApply: false,
        postStatus: "Applied",
        matchedAt: "14-Jun-23",
        score: "40.10%",
        hrEmail: "hr@wipro.com",
        jobLink: "https://www.foundit.in/",
        jobDescription: {
            responsibility: [
                "Ensuring an uninterrupted flow of data from the various sources by crawling the web",
                "Extracting & managing large volumes of structured and unstructured data, with the ability to parse data into standardized format for ingestion into data sources",
                "Actively participate in troubleshooting, debugging & maintaining the broken crawlers",
                "Scraping difficult websites by deploying anti-blocking and anti-captcha tools",
                "Strong data analysis skills working with data quality, data consolidation and data wrangling",
                "Solid understanding of Data structures and Algorithms",
                "Comply with coding standards and technical design"
            ],
            requirements: [
                "Education: B.E / B.Tech / BSC/ MSC",
                "Experience : 0-1 year",
                "KeySkills: Python, Perl, Scrapy, Selenium, headless browsers, Puppeteer, Node.js, Beautiful Soup, sVN, GitHub",
                "Experience of complex crawling like captcha, recaptcha and bypassing proxy, etc",
                "Regular Expressions",
                "Basic understanding of front-end technologies, such as JavaScript, HTML5, and CSS3.",
                "Strong fundamental C.S. skills (Data structures, algorithms, multi-threading, etc.)",
                "Good communication skills (must)",
                "Experience with web crawler projects is a plus."
            ]
        }
    },
    {
        id: 3,
        CandidateName:' Travis Howard',
        jobTitle: "Nodejs Developer",
        company: "Infosys",
        location: "Mumbai",
        platform: "Glass Door",
        isApply: false,
        postStatus: "Rejected",
        matchedAt: "14-Jun-23",
        score: "64.54%",
        hrEmail: "hr@infosys.com",
        jobLink: "https://www.glassdoor.co.in/",
        jobDescription: {
            responsibility: [
                "Ensuring an uninterrupted flow of data from the various sources by crawling the web",
                "Extracting & managing large volumes of structured and unstructured data, with the ability to parse data into standardized format for ingestion into data sources",
                "Actively participate in troubleshooting, debugging & maintaining the broken crawlers",
                "Scraping difficult websites by deploying anti-blocking and anti-captcha tools",
                "Strong data analysis skills working with data quality, data consolidation and data wrangling",
                "Solid understanding of Data structures and Algorithms",
                "Comply with coding standards and technical design"
            ],
            requirements: [
                "Education: B.E / B.Tech / BSC/ MSC",
                "Experience : 0-1 year",
                "KeySkills: Python, Perl, Scrapy, Selenium, headless browsers, Puppeteer, Node.js, Beautiful Soup, sVN, GitHub",
                "Experience of complex crawling like captcha, recaptcha and bypassing proxy, etc",
                "Regular Expressions",
                "Basic understanding of front-end technologies, such as JavaScript, HTML5, and CSS3.",
                "Strong fundamental C.S. skills (Data structures, algorithms, multi-threading, etc.)",
                "Good communication skills (must)",
                "Experience with web crawler projects is a plus."
            ]
        }
    },
    {
        id: 4,
        CandidateName:'Harmayni craft',
        jobTitle: "Backend Developer",
        company: "Capgemini",
        location: "Banglore",
        platform: "LinkedIn",
        isApply: false,
        postStatus: "Apply",
        matchedAt: "14-Jun-23",
        score: "54.75%",
        hrEmail: "hr@capgemini.com",
        jobLink: "https://www.linkedin.com",
        jobDescription: {
            responsibility: [
                "Ensuring an uninterrupted flow of data from the various sources by crawling the web",
                "Extracting & managing large volumes of structured and unstructured data, with the ability to parse data into standardized format for ingestion into data sources",
                "Actively participate in troubleshooting, debugging & maintaining the broken crawlers",
                "Scraping difficult websites by deploying anti-blocking and anti-captcha tools",
                "Strong data analysis skills working with data quality, data consolidation and data wrangling",
                "Solid understanding of Data structures and Algorithms",
                "Comply with coding standards and technical design"
            ],
            requirements: [
                "Education: B.E / B.Tech / BSC/ MSC",
                "Experience : 0-1 year",
                "KeySkills: Python, Perl, Scrapy, Selenium, headless browsers, Puppeteer, Node.js, Beautiful Soup, sVN, GitHub",
                "Experience of complex crawling like captcha, recaptcha and bypassing proxy, etc",
                "Regular Expressions",
                "Basic understanding of front-end technologies, such as JavaScript, HTML5, and CSS3.",
                "Strong fundamental C.S. skills (Data structures, algorithms, multi-threading, etc.)",
                "Good communication skills (must)",
                "Experience with web crawler projects is a plus."
            ]
        }
    },
    {
        id: 5,
        CandidateName:' Jacky roy',
        jobTitle: "Java Backend Developer",
        company: "Accenture",
        location: "Hyderabad",
        platform: "Monster",
        isApply: false,
        postStatus: "Applied",
        matchedAt: "14-Jun-23",
        score: "45.73%",
        hrEmail: "hr@accenture.com",
        jobLink: "https://www.foundit.in/",
        jobDescription: {
            responsibility: [
                "Ensuring an uninterrupted flow of data from the various sources by crawling the web",
                "Extracting & managing large volumes of structured and unstructured data, with the ability to parse data into standardized format for ingestion into data sources",
                "Actively participate in troubleshooting, debugging & maintaining the broken crawlers",
                "Scraping difficult websites by deploying anti-blocking and anti-captcha tools",
                "Strong data analysis skills working with data quality, data consolidation and data wrangling",
                "Solid understanding of Data structures and Algorithms",
                "Comply with coding standards and technical design"
            ],
            requirements: [
                "Education: B.E / B.Tech / BSC/ MSC",
                "Experience : 0-1 year",
                "KeySkills: Python, Perl, Scrapy, Selenium, headless browsers, Puppeteer, Node.js, Beautiful Soup, sVN, GitHub",
                "Experience of complex crawling like captcha, recaptcha and bypassing proxy, etc",
                "Regular Expressions",
                "Basic understanding of front-end technologies, such as JavaScript, HTML5, and CSS3.",
                "Strong fundamental C.S. skills (Data structures, algorithms, multi-threading, etc.)",
                "Good communication skills (must)",
                "Experience with web crawler projects is a plus."
            ]
        }
    },
    {
        id: 6,
        CandidateName:'Amily Johnson',
        jobTitle: "MERN Stack Developer",
        company: "TCS",
        location: "Delhi",
        platform: "Naukri",
        isApply: false,
        postStatus: "Rejected",
        matchedAt: "14-Jun-23",
        score: "76.05%",
        hrEmail: "hr@tcs.com",
        jobLink: "https://www.naukri.com/",
        jobDescription: {
            responsibility: [
                "Ensuring an uninterrupted flow of data from the various sources by crawling the web",
                "Extracting & managing large volumes of structured and unstructured data, with the ability to parse data into standardized format for ingestion into data sources",
                "Actively participate in troubleshooting, debugging & maintaining the broken crawlers",
                "Scraping difficult websites by deploying anti-blocking and anti-captcha tools",
                "Strong data analysis skills working with data quality, data consolidation and data wrangling",
                "Solid understanding of Data structures and Algorithms",
                "Comply with coding standards and technical design"
            ],
            requirements: [
                "Education: B.E / B.Tech / BSC/ MSC",
                "Experience : 0-1 year",
                "KeySkills: Python, Perl, Scrapy, Selenium, headless browsers, Puppeteer, Node.js, Beautiful Soup, sVN, GitHub",
                "Experience of complex crawling like captcha, recaptcha and bypassing proxy, etc",
                "Regular Expressions",
                "Basic understanding of front-end technologies, such as JavaScript, HTML5, and CSS3.",
                "Strong fundamental C.S. skills (Data structures, algorithms, multi-threading, etc.)",
                "Good communication skills (must)",
                "Experience with web crawler projects is a plus."
            ]
        }
    },
    {
        id: 7,
        CandidateName:' Garry Sobars',
        jobTitle: "React Developer",
        company: "HCL",
        location: "Chennai",
        platform: "Freshers World",
        isApply: false,
        postStatus: "Apply",
        matchedAt: "14-Jun-23",
        score: "78.95%",
        hrEmail: "hr@hcl.com",
        jobLink: "https://www.freshersworld.com/",
        jobDescription: {
            responsibility: [
                "Ensuring an uninterrupted flow of data from the various sources by crawling the web",
                "Extracting & managing large volumes of structured and unstructured data, with the ability to parse data into standardized format for ingestion into data sources",
                "Actively participate in troubleshooting, debugging & maintaining the broken crawlers",
                "Scraping difficult websites by deploying anti-blocking and anti-captcha tools",
                "Strong data analysis skills working with data quality, data consolidation and data wrangling",
                "Solid understanding of Data structures and Algorithms",
                "Comply with coding standards and technical design"
            ],
            requirements: [
                "Education: B.E / B.Tech / BSC/ MSC",
                "Experience : 0-1 year",
                "KeySkills: Python, Perl, Scrapy, Selenium, headless browsers, Puppeteer, Node.js, Beautiful Soup, sVN, GitHub",
                "Experience of complex crawling like captcha, recaptcha and bypassing proxy, etc",
                "Regular Expressions",
                "Basic understanding of front-end technologies, such as JavaScript, HTML5, and CSS3.",
                "Strong fundamental C.S. skills (Data structures, algorithms, multi-threading, etc.)",
                "Good communication skills (must)",
                "Experience with web crawler projects is a plus."
            ]
        }
    },
    {
        id: 8,
        CandidateName:' Jacky Roy',
        jobTitle: "GraphQL Developer",
        company: "Accenture",
        location: "Kolkatta",
        platform: "Naukri",
        isApply: false,
        postStatus: "Applied",
        matchedAt: "14-Jun-23",
        score: "78.15%",
        hrEmail: "hr@accenture.com",
        jobLink: "https://www.naukri.com/",
        jobDescription: {
            responsibility: [
                "Ensuring an uninterrupted flow of data from the various sources by crawling the web",
                "Extracting & managing large volumes of structured and unstructured data, with the ability to parse data into standardized format for ingestion into data sources",
                "Actively participate in troubleshooting, debugging & maintaining the broken crawlers",
                "Scraping difficult websites by deploying anti-blocking and anti-captcha tools",
                "Strong data analysis skills working with data quality, data consolidation and data wrangling",
                "Solid understanding of Data structures and Algorithms",
                "Comply with coding standards and technical design"
            ],
            requirements: [
                "Education: B.E / B.Tech / BSC/ MSC",
                "Experience : 0-1 year",
                "KeySkills: Python, Perl, Scrapy, Selenium, headless browsers, Puppeteer, Node.js, Beautiful Soup, sVN, GitHub",
                "Experience of complex crawling like captcha, recaptcha and bypassing proxy, etc",
                "Regular Expressions",
                "Basic understanding of front-end technologies, such as JavaScript, HTML5, and CSS3.",
                "Strong fundamental C.S. skills (Data structures, algorithms, multi-threading, etc.)",
                "Good communication skills (must)",
                "Experience with web crawler projects is a plus."
            ]
        }
    },
    {
        id: 9,
        CandidateName:' Joe Root ',
        jobTitle: "Database Engineer",
        company: "Paytm",
        location: "Banglore",
        platform: "LinkedIn",
        isApply: false,
        postStatus: "Rejected",
        matchedAt: "14-Jun-23",
        score: "45.73%",
        hrEmail: "hr@paytm.com",
        jobLink: "https://www.linkedin.com",
        jobDescription: {
            responsibility: [
                "Ensuring an uninterrupted flow of data from the various sources by crawling the web",
                "Extracting & managing large volumes of structured and unstructured data, with the ability to parse data into standardized format for ingestion into data sources",
                "Actively participate in troubleshooting, debugging & maintaining the broken crawlers",
                "Scraping difficult websites by deploying anti-blocking and anti-captcha tools",
                "Strong data analysis skills working with data quality, data consolidation and data wrangling",
                "Solid understanding of Data structures and Algorithms",
                "Comply with coding standards and technical design"
            ],
            requirements: [
                "Education: B.E / B.Tech / BSC/ MSC",
                "Experience : 0-1 year",
                "KeySkills: Python, Perl, Scrapy, Selenium, headless browsers, Puppeteer, Node.js, Beautiful Soup, sVN, GitHub",
                "Experience of complex crawling like captcha, recaptcha and bypassing proxy, etc",
                "Regular Expressions",
                "Basic understanding of front-end technologies, such as JavaScript, HTML5, and CSS3.",
                "Strong fundamental C.S. skills (Data structures, algorithms, multi-threading, etc.)",
                "Good communication skills (must)",
                "Experience with web crawler projects is a plus."
            ]
        }
    },
    {
        id: 10,
        CandidateName:' Robert Twose',
        jobTitle: "Deployment Engineer",
        company: "Phone pay",
        location: "Pune",
        platform: "LinkedIn",
        isApply: false,
        postStatus: "Apply",
        matchedAt: "14-Jun-23",
        score: "89.73%",
        hrEmail: "hr@phonepay.com",
        jobLink: "https://www.linkedin.com",
        jobDescription: {
            responsibility: [
                "Ensuring an uninterrupted flow of data from the various sources by crawling the web",
                "Extracting & managing large volumes of structured and unstructured data, with the ability to parse data into standardized format for ingestion into data sources",
                "Actively participate in troubleshooting, debugging & maintaining the broken crawlers",
                "Scraping difficult websites by deploying anti-blocking and anti-captcha tools",
                "Strong data analysis skills working with data quality, data consolidation and data wrangling",
                "Solid understanding of Data structures and Algorithms",
                "Comply with coding standards and technical design"
            ],
            requirements: [
                "Education: B.E / B.Tech / BSC/ MSC",
                "Experience : 0-1 year",
                "KeySkills: Python, Perl, Scrapy, Selenium, headless browsers, Puppeteer, Node.js, Beautiful Soup, sVN, GitHub",
                "Experience of complex crawling like captcha, recaptcha and bypassing proxy, etc",
                "Regular Expressions",
                "Basic understanding of front-end technologies, such as JavaScript, HTML5, and CSS3.",
                "Strong fundamental C.S. skills (Data structures, algorithms, multi-threading, etc.)",
                "Good communication skills (must)",
                "Experience with web crawler projects is a plus."
            ]
        }
    },
    {
        id: 11,
        CandidateName:'Dhruva Sharma',
        jobTitle: "Frontend Engineer",
        company: "Phone pay",
        location: "Pune",
        platform: "LinkedIn",
        isApply: false,
        postStatus: "Placed",
        matchedAt: "14-Jun-23",
        score: "89.73%",
        hrEmail: "hr@phonepay.com",
        jobLink: "https://www.linkedin.com",
        jobDescription: {
            responsibility: [
                "Ensuring an uninterrupted flow of data from the various sources by crawling the web",
                "Extracting & managing large volumes of structured and unstructured data, with the ability to parse data into standardized format for ingestion into data sources",
                "Actively participate in troubleshooting, debugging & maintaining the broken crawlers",
                "Scraping difficult websites by deploying anti-blocking and anti-captcha tools",
                "Strong data analysis skills working with data quality, data consolidation and data wrangling",
                "Solid understanding of Data structures and Algorithms",
                "Comply with coding standards and technical design"
            ],
            requirements: [
                "Education: B.E / B.Tech / BSC/ MSC",
                "Experience : 0-1 year",
                "KeySkills: Python, Perl, Scrapy, Selenium, headless browsers, Puppeteer, Node.js, Beautiful Soup, sVN, GitHub",
                "Experience of complex crawling like captcha, recaptcha and bypassing proxy, etc",
                "Regular Expressions",
                "Basic understanding of front-end technologies, such as JavaScript, HTML5, and CSS3.",
                "Strong fundamental C.S. skills (Data structures, algorithms, multi-threading, etc.)",
                "Good communication skills (must)",
                "Experience with web crawler projects is a plus."
            ]
        }
    },
    {
        id: 12,
        CandidateName:' Albert Hall',
        jobTitle: "MERN Stack Developer",
        company: "Amazon",
        location: "Mumbai",
        platform: "LinkedIn",
        isApply: false,
        postStatus: "Placed",
        matchedAt: "14-Jun-23",
        score: "89.73%",
        hrEmail: "hr@amazon.com",
        jobLink: "https://www.linkedin.com",
        jobDescription: {
            responsibility: [
                "Ensuring an uninterrupted flow of data from the various sources by crawling the web",
                "Extracting & managing large volumes of structured and unstructured data, with the ability to parse data into standardized format for ingestion into data sources",
                "Actively participate in troubleshooting, debugging & maintaining the broken crawlers",
                "Scraping difficult websites by deploying anti-blocking and anti-captcha tools",
                "Strong data analysis skills working with data quality, data consolidation and data wrangling",
                "Solid understanding of Data structures and Algorithms",
                "Comply with coding standards and technical design"
            ],
            requirements: [
                "Education: B.E / B.Tech / BSC/ MSC",
                "Experience : 0-1 year",
                "KeySkills: Python, Perl, Scrapy, Selenium, headless browsers, Puppeteer, Node.js, Beautiful Soup, sVN, GitHub",
                "Experience of complex crawling like captcha, recaptcha and bypassing proxy, etc",
                "Regular Expressions",
                "Basic understanding of front-end technologies, such as JavaScript, HTML5, and CSS3.",
                "Strong fundamental C.S. skills (Data structures, algorithms, multi-threading, etc.)",
                "Good communication skills (must)",
                "Experience with web crawler projects is a plus."
            ]
        }
    },
    {
        id: 13,
        CandidateName:' Jackson Hall',
        jobTitle: "MERN Stack Developer",
        company: "Paytm",
        location: "Banglore",
        platform: "Naukri",
        isApply: false,
        postStatus: "Placed",
        matchedAt: "14-Jun-23",
        score: "89.73%",
        hrEmail: "hr@naukri.com",
        jobLink: "https://www.naukri.com/",
        jobDescription: {
            responsibility: [
                "Ensuring an uninterrupted flow of data from the various sources by crawling the web",
                "Extracting & managing large volumes of structured and unstructured data, with the ability to parse data into standardized format for ingestion into data sources",
                "Actively participate in troubleshooting, debugging & maintaining the broken crawlers",
                "Scraping difficult websites by deploying anti-blocking and anti-captcha tools",
                "Strong data analysis skills working with data quality, data consolidation and data wrangling",
                "Solid understanding of Data structures and Algorithms",
                "Comply with coding standards and technical design"
            ],
            requirements: [
                "Education: B.E / B.Tech / BSC/ MSC",
                "Experience : 0-1 year",
                "KeySkills: Python, Perl, Scrapy, Selenium, headless browsers, Puppeteer, Node.js, Beautiful Soup, sVN, GitHub",
                "Experience of complex crawling like captcha, recaptcha and bypassing proxy, etc",
                "Regular Expressions",
                "Basic understanding of front-end technologies, such as JavaScript, HTML5, and CSS3.",
                "Strong fundamental C.S. skills (Data structures, algorithms, multi-threading, etc.)",
                "Good communication skills (must)",
                "Experience with web crawler projects is a plus."
            ]
        }
    }
];

export default jobsList;